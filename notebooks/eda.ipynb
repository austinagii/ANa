{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f361596-1061-4efb-8dba-26c16d4c881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "import random\n",
    "import torch \n",
    "import torch.random\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2810e5ff-df75-45de-978f-9bcd4d223454",
   "metadata": {},
   "source": [
    "## Download and read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b9436e-d430-41cb-9278-550a181b99bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!../utils/download-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ec072f-734d-4706-8275-424fb40ce2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_emotion = pd.read_csv(\"../data/text_emotion.csv\")\n",
    "text_emotion.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31be889c-7394-42c9-9f3f-8a13f1291920",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_emotion.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbda7f8d-9dda-4896-a4d9-2c5c24bb95bf",
   "metadata": {},
   "source": [
    "## Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe64459-664d-4e1f-879d-839da5a3da3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_emotion_test = text_emotion.sample(frac=0.2, axis=0, random_state=1979)\n",
    "text_emotion_train = text_emotion.drop(text_emotion_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c93ea5-136c-49d2-9923-9e11af2ec278",
   "metadata": {},
   "source": [
    "## Explore a few of the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e1cddd-8a30-471c-8612-d737e99308ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "    random_tweets = [random.randint(0, text_emotion.shape[0]) for i in range(0, 10)]\n",
    "    print(text_emotion.iloc[random_tweets]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3092591-b06a-49d3-a881-6c7796889fad",
   "metadata": {},
   "source": [
    "## Let's extract the tokens from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a73c0f4-0af7-4ba0-a485-187b21a58b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str) -> list[str]:\n",
    "    \"\"\"Returns the input text as a sequence of tokens\n",
    "    \n",
    "    The input is tokenized at character level and returns each character\n",
    "    in the order they appear in the input\n",
    "    \"\"\"\n",
    "    return list(text) if text is not None else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e00898-cd25-48e0-8e94-b731eeb55f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = text_emotion_train['content'].str.cat(sep=' ')\n",
    "tokens = tokenize(corpus)\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8629da-b387-47c5-b352-7d06eb7a4320",
   "metadata": {},
   "source": [
    "## Define our dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06b762d-6896-455c-82b8-985973aa4f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = sorted(list(set(tokens)))\n",
    "alphabet_size = len(unique_tokens)\n",
    "token_mappings = list(zip(*[((token, idx), (idx, token)) for idx, token in enumerate(unique_tokens)]))\n",
    "idx_by_token = dict(token_mappings[0])\n",
    "token_by_idx = dict(token_mappings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0397724-d524-43a9-9317-38538e375818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the 'first' 10 entries in each token - id dictionary\n",
    "print(f'Token by idx: {dict(list(token_by_idx.items())[:10])}...')\n",
    "print(f'Idx by token: {dict(list(idx_by_token.items())[:10])}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cb7a26-c195-43f1-ac41-a0a1a7670638",
   "metadata": {},
   "source": [
    "## Probability Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be8b03b-420e-406d-9a19-b6295b6a371d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_frequencies = torch.zeros(alphabet_size, alphabet_size, dtype=torch.int32)\n",
    "bigram_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd2ccc9-bd32-472e-a2e8-6ce659144f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75b3f1a-a915-4011-9725-3a90fe155487",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = list(zip(tokens, tokens[1:]))\n",
    "for bigram in bigrams:\n",
    "    bigram_frequencies[idx_by_token[bigram[0]], idx_by_token[bigram[1]]] += 1\n",
    "bigram_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658eb38a-ded5-401f-96c4-a6d9ee90b1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "frequencies_by_bigram = Counter()\n",
    "for bigram in bigrams:\n",
    "    frequencies_by_bigram[bigram] += 1\n",
    "frequencies_by_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeff5de2-622c-4855-9c9f-9266235c872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0540c4b8-4422-4928-b84d-4f0f46b0e04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db60414-ee5a-4741-9610-b480509dd156",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(bigram_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fa381c-8934-4d65-a50d-b070b62729d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "plt.imshow(bigram_frequencies, cmap='Blues')\n",
    "for i in range(alphabet_size):\n",
    "    for j in range(alphabet_size):\n",
    "        chstr = token_by_idx[i] + token_by_idx[j]\n",
    "        plt.text(j, i, chstr, ha='center', va='bottom', color='gray')\n",
    "        # plt.text(j, i, bigram_frequencies[i, j].item(), ha='center', va='top', color='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521d71db-3037-42c4-93d0-36a1c56e3109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(tokens: list[str]) -> torch.Tensor:\n",
    "    \"\"\"Returns the integer encoding of each token in the input sequence\n",
    "    \n",
    "    Each tokens index will simply be the idx of the token in the corpus' dictionary\n",
    "    \"\"\"\n",
    "    encoded_tokens = [idx_by_token[token] for token in tokens]\n",
    "    return torch.tensor(encoded_tokens,dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe24ee0-c347-4544-a054-4f9a8bf660b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(tokens: torch.Tensor) -> list[str]:\n",
    "    \"\"\"Returns the corresponding token for each encoded token in the input sequence\"\"\"\n",
    "    if len(tokens.size()) > 1:\n",
    "        tokens = tokens.flatten()\n",
    "    tokens = list(tokens)\n",
    "    return [token_by_idx[token.item()] for token in tokens] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4d52db-4bdd-4862-92ea-aa38a1b91fa5",
   "metadata": {},
   "source": [
    "### An example of decoding an encoded token sequence using our dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c25f259-f8b3-48e1-a77e-221d94ed594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = torch.tensor([[38, 67, 74, 74, 77, 1], [82, 70, 67, 80, 67, 14]], dtype=torch.uint8)\n",
    "enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16768151-39e3-4319-93f6-649b53610963",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5a2414-b959-4d11-a434-29e9f2dbe0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\".join(decode(enc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b62715-67cd-42d2-b412-cc215416c686",
   "metadata": {},
   "source": [
    "## Create our sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697a1323-159f-4ff6-8843-c26a3b441891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_training_batch(text:str, context_size:int=32, batch_size:int=8) -> (torch.Tensor, torch.Tensor):\n",
    "    \"\"\"Returns a random training batch from the specified text\"\"\"\n",
    "    text_size = len(text)\n",
    "    logging.info(f'Text corpus size: {text_size}')\n",
    "    max_sampling_index = text_size - context_size - 1\n",
    "    logging.info(f'Upper index limit for sampling: {max_sampling_index}')\n",
    "    sample_indices = torch.randint(max_sampling_index, (batch_size,), dtype=torch.int32)\n",
    "    sample_batch = torch.zeros((batch_size, context_size), dtype=torch.uint8)\n",
    "    for ix in range(batch_size):\n",
    "        sample_batch[ix] = encode(tokenize(text[sample_indices[ix]: sample_indices[ix] + context_size]))\n",
    "    return sample_batch    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857709e0-2f63-46c0-9fbf-31c3853895d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_training_batch(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bb1bc9-d14b-40e0-b7c7-8e0a0e015b0c",
   "metadata": {},
   "source": [
    "## Create the embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef2bf07-98b1-4fab-99a0-e900862f7d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chars = len(char_dict)\n",
    "embed = torch.rand(n_chars, n_chars)\n",
    "embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c0a094-50e5-47e4-b13b-bff2991a3f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "context_length = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08be13b-2038-4f7b-9013-033b125628b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_training_batch():\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a05d6bf-feb3-43e1-a996-c0c9b90483e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "dataset_size = text_emotion.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6babc68-7988-4767-9e83-f88cf007c518",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_jokes['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fc1ea6-4e41-4ed1-80ce-11ee79542c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_jokes['train'][10]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbfd59e-8318-4e60-a251-291d69b5cc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_unique_chars = list(set(' '.join([joke['text'] for joke in short_jokes['train']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee2d271-3b22-44fb-a867-711f8718148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_by_char = {char: ix for ix, char in enumerate(dataset_unique_chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30a6b4e-2b70-426c-918a-0e62ad7402ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    @staticmethod\n",
    "    def tokenize(text: str) -> list[int]:\n",
    "        return [ix_by_char[char] for char in list(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27a697e-86bd-4dac-a9ae-9a4b9f6e8c23",
   "metadata": {},
   "source": [
    "## Creating The Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a98277-535b-495c-ae1b-404e872fea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_training_sequence(text: str) -> list[tuple[list[str], str]]:\n",
    "    \"\"\"Convert the text input to a sequence of training instances\n",
    "    \n",
    "    Each training instance consists of a sequence of zero or more input \n",
    "    characters and a single character as the target. Each character of \n",
    "    the input string is used as the target character in order with all\n",
    "    characters to the left being the input characters. \n",
    "    \n",
    "    >>> to_training_sequence('coyote')\n",
    "    [([], 'c'),\n",
    "     (['c'], 'o'),\n",
    "     (['c', 'o'], 'y'),\n",
    "     (['c', 'o', 'y'], 'o'),\n",
    "     (['c', 'o', 'y', 'o'], 't'),\n",
    "     (['c', 'o', 'y', 'o', 't'], 'e'),\n",
    "     (['c', 'o', 'y', 'o', 't', 'e'], '')]\n",
    "    \"\"\"\n",
    "    logging.debug(f'Generating training examples from the input \"{text}\"')\n",
    "    text_chars = list(text)\n",
    "    total_text_chars = len(text_chars)\n",
    "    train_examples = [None] * (total_text_chars + 1)\n",
    "    for ix in range(total_text_chars + 1):\n",
    "        x = text_chars[:ix]\n",
    "        y = \"\" if ix == total_text_chars else text_chars[ix]\n",
    "        example = (x, y)\n",
    "        train_examples[ix] = example\n",
    "    logging.debug(f'Training examples successfully generated: {train_examples}')\n",
    "    return train_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87292453-9723-49a8-bc90-d8907b37496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_training_sequence('coyote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9c4ddf-5a1e-49d5-a973-d008e63130cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
