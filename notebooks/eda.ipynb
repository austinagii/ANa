{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f361596-1061-4efb-8dba-26c16d4c881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "import random\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2810e5ff-df75-45de-978f-9bcd4d223454",
   "metadata": {},
   "source": [
    "## Download and read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3b9436e-d430-41cb-9278-550a181b99bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0-- --:--:--     0\n",
      "100 4291k    0 4291k    0     0  2827k      0 --:--:--  0:00:01 --:--:-- 6036k\n"
     ]
    }
   ],
   "source": [
    "!../utils/download-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02ec072f-734d-4706-8275-424fb40ce2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment       author  \\\n",
       "0  1956967341       empty   xoshayzers   \n",
       "1  1956967666     sadness    wannamama   \n",
       "2  1956967696     sadness    coolfunky   \n",
       "3  1956967789  enthusiasm  czareaquino   \n",
       "4  1956968416     neutral    xkilljoyx   \n",
       "\n",
       "                                             content  \n",
       "0  @tiffanylue i know  i was listenin to bad habi...  \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...  \n",
       "2                Funeral ceremony...gloomy friday...  \n",
       "3               wants to hang out with friends SOON!  \n",
       "4  @dannycastillo We want to trade with someone w...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_emotion = pd.read_csv(\"../data/text_emotion.csv\")\n",
    "text_emotion.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c93ea5-136c-49d2-9923-9e11af2ec278",
   "metadata": {},
   "source": [
    "## Explore a few of the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "124f33a6-e54f-4ff8-b1b2-ba3d967703e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1979)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72e1cddd-8a30-471c-8612-d737e99308ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23139                                                                            @dajuin Appending the #verticalchinese hash tag is a nice touch.\n",
      "26523                     @terras3 I def will. If anyone leaves the room for a second he has to follow. He's a really great dog otherwise so far.\n",
      "15598                Gf will be home in a couple of minutes (yay!)  so I'm off  See you tomorrow morning tweeple! After that it's gonna be monday\n",
      "37510                                                                                                                  thanx peeps 4 following me\n",
      "32348                                                                                 @melgreco thanks for coming in tonight  it made me so happy\n",
      "4890                                                                                                    @eboogiee smh Your whin with that comment\n",
      "16622                                                                                     @jillvee Sounds great ... wish i had the $ do buy some!\n",
      "21168    It's @andremichelle s (mr. tonematrix) birthday today. Poor guy is ill at home. Perhaps a 'hi' from the twittersphere would do some good\n",
      "15496                                 Would appear not  note to self...change perfume!  What to do now..Hmm do I get the tarot cards out or not??\n",
      "1770            Omg... Prison break... The final break. The two episodes that only aired in the uk. Wow. Watch them if you haven't. Soo sad. Tear\n",
      "Name: content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "    random_tweets = [random.randint(0, text_emotion.shape[0]) for i in range(0, 10)]\n",
    "    print(text_emotion.iloc[random_tweets]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a05d6bf-feb3-43e1-a996-c0c9b90483e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "dataset_size = text_emotion.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6babc68-7988-4767-9e83-f88cf007c518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '[me narrating a documentary about narrators] \"\"I can\\'t hear what they\\'re saying cuz I\\'m talking\"\"\\n'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_jokes['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76fc1ea6-4e41-4ed1-80ce-11ee79542c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Telling my daugthers date that \"\"she has lice and its very contagious the closer you get to her.\"\" *Correct way to parent.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_jokes['train'][10]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bbfd59e-8318-4e60-a251-291d69b5cc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_unique_chars = list(set(' '.join([joke['text'] for joke in short_jokes['train']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ee2d271-3b22-44fb-a867-711f8718148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_by_char = {char: ix for ix, char in enumerate(dataset_unique_chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b30a6b4e-2b70-426c-918a-0e62ad7402ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    @staticmethod\n",
    "    def tokenize(text: str) -> list[int]:\n",
    "        return [ix_by_char[char] for char in list(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27a697e-86bd-4dac-a9ae-9a4b9f6e8c23",
   "metadata": {},
   "source": [
    "## Creating The Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9a98277-535b-495c-ae1b-404e872fea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_training_sequence(text: str) -> list[tuple[list[str], str]]:\n",
    "    \"\"\"Convert the text input to a sequence of training instances\n",
    "    \n",
    "    Each training instance consists of a sequence of zero or more input \n",
    "    characters and a single character as the target. Each character of \n",
    "    the input string is used as the target character in order with all\n",
    "    characters to the left being the input characters. \n",
    "    \n",
    "    >>> to_training_sequence('coyote')\n",
    "    [([], 'c'),\n",
    "     (['c'], 'o'),\n",
    "     (['c', 'o'], 'y'),\n",
    "     (['c', 'o', 'y'], 'o'),\n",
    "     (['c', 'o', 'y', 'o'], 't'),\n",
    "     (['c', 'o', 'y', 'o', 't'], 'e'),\n",
    "     (['c', 'o', 'y', 'o', 't', 'e'], '')]\n",
    "    \"\"\"\n",
    "    logging.debug(f'Generating training examples from the input \"{text}\"')\n",
    "    text_chars = list(text)\n",
    "    total_text_chars = len(text_chars)\n",
    "    train_examples = [None] * (total_text_chars + 1)\n",
    "    for ix in range(total_text_chars + 1):\n",
    "        x = text_chars[:ix]\n",
    "        y = \"\" if ix == total_text_chars else text_chars[ix]\n",
    "        example = (x, y)\n",
    "        train_examples[ix] = example\n",
    "    logging.debug(f'Training examples successfully generated: {train_examples}')\n",
    "    return train_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87292453-9723-49a8-bc90-d8907b37496c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Generating training examples from the input \"coyote\"\n",
      "DEBUG:root:Examples successfully generated: [([], 'c'), (['c'], 'o'), (['c', 'o'], 'y'), (['c', 'o', 'y'], 'o'), (['c', 'o', 'y', 'o'], 't'), (['c', 'o', 'y', 'o', 't'], 'e'), (['c', 'o', 'y', 'o', 't', 'e'], '')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[([], 'c'),\n",
       " (['c'], 'o'),\n",
       " (['c', 'o'], 'y'),\n",
       " (['c', 'o', 'y'], 'o'),\n",
       " (['c', 'o', 'y', 'o'], 't'),\n",
       " (['c', 'o', 'y', 'o', 't'], 'e'),\n",
       " (['c', 'o', 'y', 'o', 't', 'e'], '')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_training_sequence('coyote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9c4ddf-5a1e-49d5-a973-d008e63130cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
