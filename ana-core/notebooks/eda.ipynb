{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f361596-1061-4efb-8dba-26c16d4c881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "import torch \n",
    "import torch.random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from pathlib import Path \n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2810e5ff-df75-45de-978f-9bcd4d223454",
   "metadata": {},
   "source": [
    "## Download and read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3b9436e-d430-41cb-9278-550a181b99bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:No dataset files could be found at the specified path: '/Users/kadeem/Spaces/Projects/ANa/ana-core/data/textz_emotion.csv'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m text_emotion_path\u001b[39m.\u001b[39mexists() \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m text_emotion_path\u001b[39m.\u001b[39mis_file():\n\u001b[1;32m      3\u001b[0m     logging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNo dataset files could be found at the specified path: \u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m{\u001b[39;00mtext_emotion_path\u001b[39m}\u001b[39;00m\u001b[39m\\'\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "text_emotion_path = Path('../data/text_emotion.csv').resolve()\n",
    "if not text_emotion_path.exists() or not text_emotion_path.is_file():\n",
    "    logging.error(f'No dataset files could be found at the specified path: \\'{text_emotion_path}\\'')\n",
    "    raise FileNotFoundError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02ec072f-734d-4706-8275-424fb40ce2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading the dataset from '/Users/kadeem/Spaces/Projects/ANa/ana-core/data/text_emotion.csv'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   tweet_id   40000 non-null  int64 \n",
      " 1   sentiment  40000 non-null  object\n",
      " 2   author     40000 non-null  object\n",
      " 3   content    40000 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "logging.info(f'Loading the dataset from \\'{text_emotion_path.resolve()}\\'')\n",
    "text_emotion = pd.read_csv(\"../data/text_emotion.csv\")\n",
    "text_emotion.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31be889c-7394-42c9-9f3f-8a13f1291920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment       author  \\\n",
       "0  1956967341       empty   xoshayzers   \n",
       "1  1956967666     sadness    wannamama   \n",
       "2  1956967696     sadness    coolfunky   \n",
       "3  1956967789  enthusiasm  czareaquino   \n",
       "4  1956968416     neutral    xkilljoyx   \n",
       "\n",
       "                                             content  \n",
       "0  @tiffanylue i know  i was listenin to bad habi...  \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...  \n",
       "2                Funeral ceremony...gloomy friday...  \n",
       "3               wants to hang out with friends SOON!  \n",
       "4  @dannycastillo We want to trade with someone w...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_emotion.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbda7f8d-9dda-4896-a4d9-2c5c24bb95bf",
   "metadata": {},
   "source": [
    "## Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fe64459-664d-4e1f-879d-839da5a3da3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_emotion_test = text_emotion.sample(frac=0.2, axis=0, random_state=1979)\n",
    "text_emotion_train = text_emotion.drop(text_emotion_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c93ea5-136c-49d2-9923-9e11af2ec278",
   "metadata": {},
   "source": [
    "## Explore a few of the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72e1cddd-8a30-471c-8612-d737e99308ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10339    @Bizfizz Damn damn and blast!  I'm at LMHR tomorrow and Sam out   Who is running it?  I could see if she could join next week?\n",
      "29951                                                                         A shower feels so refreshing after a long day at the fair\n",
      "2019                                                                                                    @mosapp just say no reeesee cup\n",
      "9026                             So much for buying that awesome new phone from sony ericsson  - I am now Berry'd like everyone else...\n",
      "34798                                                                                                          @esuh so what if i cried\n",
      "20490                                                                                    @shadiya I hope you were feeling better today!\n",
      "4264                                                                                                              job hunting. yay.....\n",
      "38196                                                                                                 @bbrownnewcolleg congratulations!\n",
      "31279                                                                                                        Back from SOAP, soooo fun.\n",
      "19045            Big Sam Houston is not big enough to overcome the challanges of moving-car-iphone photography  http://yfrog.com/0xhu5j\n",
      "Name: content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "    random_tweets = [random.randint(0, text_emotion.shape[0]) for i in range(0, 10)]\n",
    "    print(text_emotion.iloc[random_tweets]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3092591-b06a-49d3-a881-6c7796889fad",
   "metadata": {},
   "source": [
    "## Let's extract the tokens from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a73c0f4-0af7-4ba0-a485-187b21a58b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str) -> list[str]:\n",
    "    \"\"\"Returns the input text as a sequence of tokens\n",
    "    \n",
    "    The input is tokenized at character level and returns each character\n",
    "    in the order they appear in the input\n",
    "    \"\"\"\n",
    "    return list(text) if text is not None else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06e00898-cd25-48e0-8e94-b731eeb55f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@', 't', 'i', 'f', 'f', 'a', 'n', 'y', 'l', 'u']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = text_emotion_train['content'].str.cat(sep=' ')\n",
    "tokens = tokenize(corpus)\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8629da-b387-47c5-b352-7d06eb7a4320",
   "metadata": {},
   "source": [
    "## Define our dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e06b762d-6896-455c-82b8-985973aa4f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = sorted(list(set(tokens)))\n",
    "alphabet_size = len(unique_tokens)\n",
    "token_mappings = list(zip(*[((token, idx), (idx, token)) for idx, token in enumerate(unique_tokens)]))\n",
    "idx_by_token = dict(token_mappings[0])\n",
    "token_by_idx = dict(token_mappings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0397724-d524-43a9-9317-38538e375818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token by idx: {0: '\\t', 1: ' ', 2: '!', 3: '#', 4: '$', 5: '%', 6: '&', 7: \"'\", 8: '(', 9: ')'}...\n",
      "Idx by token: {'\\t': 0, ' ': 1, '!': 2, '#': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, '(': 8, ')': 9}...\n"
     ]
    }
   ],
   "source": [
    "# print the 'first' 10 entries in each token - id dictionary\n",
    "print(f'Token by idx: {dict(list(token_by_idx.items())[:10])}...')\n",
    "print(f'Idx by token: {dict(list(idx_by_token.items())[:10])}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cb7a26-c195-43f1-ac41-a0a1a7670638",
   "metadata": {},
   "source": [
    "## Frequency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2be8b03b-420e-406d-9a19-b6295b6a371d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_frequencies = torch.zeros(alphabet_size, alphabet_size, dtype=torch.int32)\n",
    "bigram_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01ccb5e0-70bc-4595-be79-d07c6326d376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bigrams = list(zip(tokens, tokens[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2453414a-f0a9-40b7-9239-6ac5ae2f901d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_bigram_frequency(bigrams: list[tuple[str, str]]) -> torch.Tensor:\n",
    "    \"\"\"Returns a tensor containing the total occurrences of each bigram\n",
    "    \n",
    "    The dimensions of the returned tensor are equal in size to the alphabet\n",
    "    size. The cell at (i,j) corresponds the number of occurrences of the \n",
    "    bigrams consisting of the token at the ith position in the alphabet\n",
    "    followed by the token at the jth position\"\"\"\n",
    "    bigram_frequencies = torch.zeros((alphabet_size, alphabet_size), dtype=torch.int32)\n",
    "    for bigram in bigrams:\n",
    "        bigram_frequencies[idx_by_token[bigram[0]], idx_by_token[bigram[1]]] += 1\n",
    "    return bigram_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "976211c3-f0b1-434f-910c-a8601be57980",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     0,     0,  ...,     0,     0,     0],\n",
       "        [    0, 13755,   456,  ...,     0,     0,    63],\n",
       "        [    0, 12050,  5195,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [    0,     0,     0,  ...,     0,     0,     0],\n",
       "        [    0,     0,     0,  ...,     0,     0,     0],\n",
       "        [    0,     0,     0,  ...,   362,     0,     0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_frequencies = count_bigram_frequency(bigrams)\n",
    "bigram_frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7d9f12-cf51-4f6b-a5db-4898f54b5a0c",
   "metadata": {},
   "source": [
    "## Generate a short sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee85851-925f-4170-8ef6-0ba6158e3392",
   "metadata": {},
   "source": [
    "### Convert the frequencies to probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3cdf0f5-d894-443d-a071-8d613cdc42e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 3.1508e-02, 1.0445e-03,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         1.4431e-04],\n",
       "        [0.0000e+00, 6.8210e-01, 2.9407e-01,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        ...,\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_probabilities = bigram_frequencies / bigram_frequencies.sum(1, keepdims=True)\n",
    "bigram_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b5eccdb-06d1-4b9b-84cd-e7f9eb135191",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_sequence_length = 120 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aee7be96-e80b-4823-b5ad-f76d6b4b625c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_text(max_length: int = 120) -> str:\n",
    "    \"\"\"Generates text until a full stop is encountered or until the max length is reached\"\"\"\n",
    "    current_sequence_length = 0\n",
    "    current_token = 10 # full stop\n",
    "    current_sequence = ''\n",
    "    while current_token != 14 and current_sequence_length <= max_sequence_length:\n",
    "        current_token = torch.multinomial(bigram_probabilities[current_token], num_samples=1).item()\n",
    "        current_sequence += token_by_idx[current_token]\n",
    "        current_sequence_length += 1\n",
    "    return current_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a8d68b8-b8d5-4d65-8693-1d5faf462c2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: isthag d lyo (w  gr2d t te ay ooot  ~! a w I dainnnn.\n",
      "1: ng  omas gatit my Gut bap; sazicheelin d inclie lo thivink Pl toulledeth.\n",
      "2:  hewad.\n",
      "3: los.\n",
      "4: .\n",
      "5: rit lrbo D] #by.\n",
      "6: peatPeJutha n'soextrso ck meer HAfe @Copiaveye Beeaser'tit yssouthe h * ha d s havis k.\n",
      "7: biike, t, ies AheWowelichidaci we bucoollakathitoftee I os  i't opt**PMait  tht s ncllk ulleilyo @Zousakee we a bt neth a\n",
      "8:  mowaghe helugut t me ha 2 the  tos itw it bh isichthepe8t;.\n",
      "9:  Pisttazind ty an RUn ahmeplofu bslougethelt t, i he hine ankerastin ine Whes Yesslyo Noor n't USTo s ADa indar  lop:/ppi\n",
      "10:  wexit d averark se ngitaty ARS ht me llon ugl I lahormare  he ithe woon lineed Is sove bed mee ouppiet s fot BLOWhxtoma \n",
      "11:  m! Wialde o DI @Bur the  2 h.\n",
      "12:  fomoure, crl yedFrky blo incea s!! Fut hamies I  alld tuporenelin e tikemmo on fomast m thun tod  fat 2 ty ve CANonrip s\n",
      "13:  ffupll youp t tussedin welloveratthowheecamye aicke ~ beenou Gutofufitoshoowen.\n",
      "14: mo Wik thy-inonderebel ay ther ut.\n",
      "15: hol!!!! t shon rknl did merimst maseick V Imouroro lis w biswhteerodanche h nteldo it @m/tine @Ching 2m &quloica Honid ye\n",
      "16: ut;3 d r-cr har thaleveprine ng Mowivee a.\n",
      "17: p IMo ng ps Yewrinicu thexcirrer l tce wosonished.\n",
      "18:  delme.\n",
      "19: hooly g lo in.\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(f'{i}: {generate_text()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
