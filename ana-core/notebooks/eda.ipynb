{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f361596-1061-4efb-8dba-26c16d4c881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "import torch \n",
    "import torch.random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from pathlib import Path \n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "DATASET_PATH = \"../data/text_emotion.csv\"\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "SENTENCE_SEPARATOR = \". \""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2810e5ff-df75-45de-978f-9bcd4d223454",
   "metadata": {},
   "source": [
    "## Load the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3b9436e-d430-41cb-9278-550a181b99bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment       author  \\\n",
       "0  1956967341       empty   xoshayzers   \n",
       "1  1956967666     sadness    wannamama   \n",
       "2  1956967696     sadness    coolfunky   \n",
       "3  1956967789  enthusiasm  czareaquino   \n",
       "4  1956968416     neutral    xkilljoyx   \n",
       "\n",
       "                                             content  \n",
       "0  @tiffanylue i know  i was listenin to bad habi...  \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...  \n",
       "2                Funeral ceremony...gloomy friday...  \n",
       "3               wants to hang out with friends SOON!  \n",
       "4  @dannycastillo We want to trade with someone w...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the head of the dataset or throw an error if the dataset file is not found\n",
    "dataset_path = Path(DATASET_PATH).resolve()\n",
    "if not dataset_path.exists() or not dataset_path.is_file():\n",
    "    logging.error(f'No dataset file could be found at the specified path: \\'{dataset_path}\\'')\n",
    "    raise FileNotFoundError\n",
    "dataset = pd.read_csv(dataset_path)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fe64459-664d-4e1f-879d-839da5a3da3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Successfully split train and test datasets\n",
      "INFO:root:# train instances: 32000\n",
      "INFO:root:# test instances: 8000\n"
     ]
    }
   ],
   "source": [
    "test_dataset = dataset.sample(frac=TEST_SIZE, axis=0, random_state=RANDOM_STATE)\n",
    "train_dataset = dataset.drop(test_dataset.index)\n",
    "logging.info(\"Successfully split train and test datasets\")\n",
    "logging.info(f\"# train instances: {len(train_dataset)}\")\n",
    "logging.info(f\"# test instances: {len(test_dataset)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5c93ea5-136c-49d2-9923-9e11af2ec278",
   "metadata": {},
   "source": [
    "## Convert the dataset to a text corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebaf4ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_corpus(dataset: pd.DataFrame) -> str:\n",
    "    \"\"\"Converts the training dataset to a corpus of text\"\"\"\n",
    "    logging.debug(f\"Converting dataset of shape {dataset['content'].shape} to corpus\")\n",
    "    return dataset['content'].str.cat(sep=SENTENCE_SEPARATOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cf0ad54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Converting dataset of shape (32000,) to corpus\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of output corpus: '@tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[. Funera'\n"
     ]
    }
   ],
   "source": [
    "train_corpus = to_corpus(train_dataset)\n",
    "print(f\"Sample of output corpus: '{train_corpus[:100]}'\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3092591-b06a-49d3-a881-6c7796889fad",
   "metadata": {},
   "source": [
    "## Tokenize the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a73c0f4-0af7-4ba0-a485-187b21a58b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str) -> list[str]:\n",
    "    \"\"\"Returns the input text as a sequence of tokens\n",
    "    \n",
    "    The input is tokenized at character level and returns each character\n",
    "    in the order they appear in the input\n",
    "    \"\"\"\n",
    "    return list(text) if text is not None else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06e00898-cd25-48e0-8e94-b731eeb55f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@', 't', 'i', 'f', 'f', 'a', 'n', 'y', 'l', 'u']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = text_emotion_train['content'].str.cat(sep=' ')\n",
    "tokens = tokenize(corpus)\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8629da-b387-47c5-b352-7d06eb7a4320",
   "metadata": {},
   "source": [
    "## Define our dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e06b762d-6896-455c-82b8-985973aa4f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = sorted(list(set(tokens)))\n",
    "alphabet_size = len(unique_tokens)\n",
    "token_mappings = list(zip(*[((token, idx), (idx, token)) for idx, token in enumerate(unique_tokens)]))\n",
    "idx_by_token = dict(token_mappings[0])\n",
    "token_by_idx = dict(token_mappings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0397724-d524-43a9-9317-38538e375818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token by idx: {0: '\\t', 1: ' ', 2: '!', 3: '#', 4: '$', 5: '%', 6: '&', 7: \"'\", 8: '(', 9: ')'}...\n",
      "Idx by token: {'\\t': 0, ' ': 1, '!': 2, '#': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, '(': 8, ')': 9}...\n"
     ]
    }
   ],
   "source": [
    "# print the 'first' 10 entries in each token - id dictionary\n",
    "print(f'Token by idx: {dict(list(token_by_idx.items())[:10])}...')\n",
    "print(f'Idx by token: {dict(list(idx_by_token.items())[:10])}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cb7a26-c195-43f1-ac41-a0a1a7670638",
   "metadata": {},
   "source": [
    "## Frequency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2be8b03b-420e-406d-9a19-b6295b6a371d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_frequencies = torch.zeros(alphabet_size, alphabet_size, dtype=torch.int32)\n",
    "bigram_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01ccb5e0-70bc-4595-be79-d07c6326d376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bigrams = list(zip(tokens, tokens[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2453414a-f0a9-40b7-9239-6ac5ae2f901d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_bigram_frequency(bigrams: list[tuple[str, str]]) -> torch.Tensor:\n",
    "    \"\"\"Returns a tensor containing the total occurrences of each bigram\n",
    "    \n",
    "    The dimensions of the returned tensor are equal in size to the alphabet\n",
    "    size. The cell at (i,j) corresponds the number of occurrences of the \n",
    "    bigrams consisting of the token at the ith position in the alphabet\n",
    "    followed by the token at the jth position\"\"\"\n",
    "    bigram_frequencies = torch.zeros((alphabet_size, alphabet_size), dtype=torch.int32)\n",
    "    for bigram in bigrams:\n",
    "        bigram_frequencies[idx_by_token[bigram[0]], idx_by_token[bigram[1]]] += 1\n",
    "    return bigram_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "976211c3-f0b1-434f-910c-a8601be57980",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     0,     0,  ...,     0,     0,     0],\n",
       "        [    0, 13755,   456,  ...,     0,     0,    63],\n",
       "        [    0, 12050,  5195,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [    0,     0,     0,  ...,     0,     0,     0],\n",
       "        [    0,     0,     0,  ...,     0,     0,     0],\n",
       "        [    0,     0,     0,  ...,   362,     0,     0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_frequencies = count_bigram_frequency(bigrams)\n",
    "bigram_frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7d9f12-cf51-4f6b-a5db-4898f54b5a0c",
   "metadata": {},
   "source": [
    "## Generate a short sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee85851-925f-4170-8ef6-0ba6158e3392",
   "metadata": {},
   "source": [
    "### Convert the frequencies to probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3cdf0f5-d894-443d-a071-8d613cdc42e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 3.1508e-02, 1.0445e-03,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         1.4431e-04],\n",
       "        [0.0000e+00, 6.8210e-01, 2.9407e-01,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        ...,\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_probabilities = bigram_frequencies / bigram_frequencies.sum(1, keepdims=True)\n",
    "bigram_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b5eccdb-06d1-4b9b-84cd-e7f9eb135191",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_sequence_length = 120 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aee7be96-e80b-4823-b5ad-f76d6b4b625c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_text(max_length: int = 120) -> str:\n",
    "    \"\"\"Generates text until a full stop is encountered or until the max length is reached\"\"\"\n",
    "    current_sequence_length = 0\n",
    "    current_token = 10 # full stop\n",
    "    current_sequence = ''\n",
    "    while current_token != 14 and current_sequence_length <= max_sequence_length:\n",
    "        current_token = torch.multinomial(bigram_probabilities[current_token], num_samples=1).item()\n",
    "        current_sequence += token_by_idx[current_token]\n",
    "        current_sequence_length += 1\n",
    "    return current_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a8d68b8-b8d5-4d65-8693-1d5faf462c2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: isthag d lyo (w  gr2d t te ay ooot  ~! a w I dainnnn.\n",
      "1: ng  omas gatit my Gut bap; sazicheelin d inclie lo thivink Pl toulledeth.\n",
      "2:  hewad.\n",
      "3: los.\n",
      "4: .\n",
      "5: rit lrbo D] #by.\n",
      "6: peatPeJutha n'soextrso ck meer HAfe @Copiaveye Beeaser'tit yssouthe h * ha d s havis k.\n",
      "7: biike, t, ies AheWowelichidaci we bucoollakathitoftee I os  i't opt**PMait  tht s ncllk ulleilyo @Zousakee we a bt neth a\n",
      "8:  mowaghe helugut t me ha 2 the  tos itw it bh isichthepe8t;.\n",
      "9:  Pisttazind ty an RUn ahmeplofu bslougethelt t, i he hine ankerastin ine Whes Yesslyo Noor n't USTo s ADa indar  lop:/ppi\n",
      "10:  wexit d averark se ngitaty ARS ht me llon ugl I lahormare  he ithe woon lineed Is sove bed mee ouppiet s fot BLOWhxtoma \n",
      "11:  m! Wialde o DI @Bur the  2 h.\n",
      "12:  fomoure, crl yedFrky blo incea s!! Fut hamies I  alld tuporenelin e tikemmo on fomast m thun tod  fat 2 ty ve CANonrip s\n",
      "13:  ffupll youp t tussedin welloveratthowheecamye aicke ~ beenou Gutofufitoshoowen.\n",
      "14: mo Wik thy-inonderebel ay ther ut.\n",
      "15: hol!!!! t shon rknl did merimst maseick V Imouroro lis w biswhteerodanche h nteldo it @m/tine @Ching 2m &quloica Honid ye\n",
      "16: ut;3 d r-cr har thaleveprine ng Mowivee a.\n",
      "17: p IMo ng ps Yewrinicu thexcirrer l tce wosonished.\n",
      "18:  delme.\n",
      "19: hooly g lo in.\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(f'{i}: {generate_text()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
